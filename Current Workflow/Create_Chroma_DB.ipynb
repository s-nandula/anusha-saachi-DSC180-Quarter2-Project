{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd73941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import openai\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import chromadb\n",
    "import llm\n",
    "from transformers import pipeline\n",
    "import langchain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdcfa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get document IDs from SQLite DB\n",
    "def fetch_document_ids(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT goid FROM subset_table\")  # Adjust based on your table schema\n",
    "    ids = [row[0] for row in cursor.fetchall()]\n",
    "    conn.close()\n",
    "    return ids\n",
    "db_path = 'subset_data.db'\n",
    "document_ids = fetch_document_ids(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb9ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get from SQLite DB using the retrieved document IDs, store as an array\n",
    "def fetch_documents_by_ids(db_path, document_ids):\n",
    "    documents = []\n",
    "    # Open a single connection\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        for doc_id in document_ids:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"SELECT text FROM subset_table WHERE goid = ?\", (doc_id,))\n",
    "            result = cursor.fetchone()\n",
    "            if result:\n",
    "                documents.append(result[0])\n",
    "            else:\n",
    "                documents.append(None)\n",
    "    return documents\n",
    "\n",
    "documents = fetch_documents_by_ids(db_path, document_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e747395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude any Null elements\n",
    "documents = [element for element in documents if element is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0baeb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path to your model directory\n",
    "model_path = \"./multi-qa-MiniLM-L6-cos-v1/\"\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "\n",
    "# Load the model\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"./multi-qa-MiniLM-L6-cos-v1/\",  model_kwargs=model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7c9209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the first 100000 documents\n",
    "documents_array = documents[0:100000] \n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "#chunk the documents\n",
    "def split_docs(documents, chunk_size=1000, chunk_overlap=20):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    # Create a list to store the split documents\n",
    "    split_documents = []\n",
    "    # Iterate over each document string in the array\n",
    "    for doc in documents:\n",
    "        # Split the document string and add the chunks to the list\n",
    "        split_documents.extend(text_splitter.split_text(doc))\n",
    "    return split_documents\n",
    "\n",
    "# Split documents stored in the array\n",
    "docs_split = split_docs(documents_array)\n",
    "\n",
    "docs = text_splitter.create_documents(documents_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8976c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"chroma_db\"\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=docs, embedding=embeddings, persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d39714",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory=\"./chroma_db\", embedding_function=embeddings)\n",
    "vectordb._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67fbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process(documents_arr, batch_size, process_function):\n",
    "    for i in range(0, len(documents_arr), batch_size):\n",
    "        batch = documents_arr[i:i + batch_size]\n",
    "        process_function(batch)\n",
    "\n",
    "def add_to_chroma_database(batch):\n",
    "    vectordb.add_documents(documents=batch)\n",
    "\n",
    "batch_size = 41000\n",
    "\n",
    "batch_process(docs, batch_size, add_to_chroma_database)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_cuda12.2",
   "language": "python",
   "name": "conda_cuda12.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
